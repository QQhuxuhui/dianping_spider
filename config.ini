[config]
# 是否使用cookie池，使用为True，反之为False，如果为True，则Cookie（下面这个参数）不被读取，在cookies.txt中配置所有cookie
use_cookie_pool = False
# cookie 如果为不需要cookie的任务则可不填，cookie相关的具体使用规则可以查看readme中碎碎念的有关cookie
Cookie: s_ViewType=10; _lxsdk_cuid=18d545fabe7c8-0c4500dd057a0e-26001951-1fa400-18d545fabe7c8; _lxsdk=18d545fabe7c8-0c4500dd057a0e-26001951-1fa400-18d545fabe7c8; WEBDFPID=0z0z18yx30725y80121zvz0v1uzxwuxx81w454uzuv3979581yv94254-2021877573370-1706517571659AGSEEEQfd79fef3d01d5e9aadc18ccd4d0c95071527; _hc.v=aac7d8db-68d9-71c7-75fa-db420f3e97e3.1706517574; _lx_utm=utm_source%3Dgoogle%26utm_medium%3Dorganic; fspop=test; cy=92; cye=xuzhou; ctu=8991f021ef7241c2bfdee3c4f46be22218358a3162128c667663153046a876ca; dper=02024e21a927fe92e74e83047a90dd7a151272ccf1f205dbc34992c34e9828c87084382b8dfb6461560ae0d396f39656e3943fcc093ee0b0b1ad00000000ab1d0000b773ddcd120ad438f46e6861b5e89b1c0e4a62fc730c06fb41167699e0580f1f966db64e3b9f204e15fba70a3718f9ac; _lxsdk_s=18d580d7dee-abe-570-f13%7C%7C9; qruuid=570e12f9-419c-4503-b157-0d50e524d0b9; ll=7fd06e815b796be3df069dec7836c3df; Hm_lvt_602b80cf8079ae6591966cc70a3940e7=1706579496; Hm_lpvt_602b80cf8079ae6591966cc70a3940e7=1706579648
# uuid，获取方法详见文档，使用加密接口时使用
uuid : e5f18ed2-0f94-a5c1-6eba-496cdaa569fc.1623815619
# tcv，获取方法详见文档，使用加密接口时使用
tcv = zj9r0md0w5
# 默认user-agent,如果为None则为随机（仅可在不需要cookie的任务中使用,登录状态不建议随机user-agent）
user-agent = Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:87.0) Gecko/20100101 Firefox/87.0
# 保存方式  暂时支持csv和mongo
save_mode = mongo
# mongodb 链接 （mongodb://servername:port，如果本地默认端口（27017）可不填）
mongo_path = mongodb://127.0.0.1
# 累计请求多少次休息多少秒，从小到大排列。例：1,2;5,10 代表每请求1次休息2秒，每5次休息10秒。
requests_times = 1,2;3,5;10,20
[detail]
# 搜索关键字
keyword = 美食
# 位置代号，如上海为1  北京为2 广州为4，暂时不支持地名自动转换id
location_id = 92
# 频道号
channel_id = 10
# 搜索页链接，用于非'http://www.dianping.com/search/keyword/(location_id)/(channel_id)_(key_word)/p(page_nub)的情况
# 如果不填，则默认填充上述url，填充后上述参数默认无效
# 注，填充的时候需要填充到p，例如：http://www.dianping.com/dalian/ch10/g110p2 填充http://www.dianping.com/dalian/ch10/g110p
search_url =
# 是否只需要搜索页的首条内容
need_first = False
# 需要搜索的页数
need_pages = 10000
[proxy]
use_proxy = False
# ip 重复次数，由于非隧道模式时，一个ip常常有1分钟左右的有效时间，单次使用有点浪费，重复使用次数
repeat_nub = 5
# 代理模式为http提取
http_extract = True
# 代理模式为秘钥访问
key_extract = False
# http链接（秘钥模式不必填）
http_link = 
# 代理服务器
proxy_host =
# 代理服务器端口
proxy_port =
# 秘钥id（http模式不必填）
key_id =
# 秘钥key（http模式不必填）
key_key =

